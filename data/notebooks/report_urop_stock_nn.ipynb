{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd02659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Use a safe loader so the notebook can still run in environments missing the precomputed CSVs\n",
    "DATA_DIR = Path('data/notebooks')\n",
    "\n",
    "def safe_read_csv(path, **kwargs):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        print(f'[Warning] missing file: {path} -- some cells will be skipped or show placeholders')\n",
    "        return None\n",
    "    try:\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f'[Error] failed to read {path}: {e}')\n",
    "        return None\n",
    "\n",
    "metrics = safe_read_csv(DATA_DIR / 'metrics_all_symbols.csv')\n",
    "best_models = safe_read_csv(DATA_DIR / 'best_model_per_symbol.csv')\n",
    "rmse_pivot = safe_read_csv(DATA_DIR / 'rmse_pivot_table.csv')\n",
    "returns_stats = safe_read_csv(DATA_DIR / 'returns_summary_stats.csv', index_col=0)\n",
    "\n",
    "# derive a minimal UNIVERSE list if metrics available; otherwise leave empty\n",
    "if metrics is not None and 'Symbol' in metrics.columns:\n",
    "    UNIVERSE = metrics['Symbol'].unique().tolist()\n",
    "else:\n",
    "    UNIVERSE = []\n",
    "\n",
    "print(f'Loaded metrics: {metrics is not None}, best_models: {best_models is not None}, rmse_pivot: {rmse_pivot is not None}, returns_stats: {returns_stats is not None}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13716385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Only display images if they exist to keep notebook runnable in minimal environments\n",
    "image_files = [\n",
    "    DATA_DIR / 'universe_normalized_prices.png',\n",
    "    DATA_DIR / 'corr_heatmap.png',\n",
    "    DATA_DIR / 'fig_AAPL_test_models.png',\n",
    "    DATA_DIR / 'fig_SPY_test_models.png',\n",
    "    DATA_DIR / 'fig_QQQ_test_models.png',\n",
    "]\n",
    "\n",
    "for p in image_files:\n",
    "    if Path(p).exists():\n",
    "        display(Image(filename=str(p)))\n",
    "    else:\n",
    "        print(f'[Warning] image not found: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cols = [\"LSTM\", \"MA 20 day\", \"MA 5 day\", \"Naive lag1\"]\n",
    "\n",
    "if rmse_pivot is None:\n",
    "    print('[Warning] rmse_pivot_table.csv not loaded; skipping winner count computation')\n",
    "    winner_counts = None\n",
    "else:\n",
    "    winner_counts = (\n",
    "        rmse_pivot.set_index('Symbol')[rmse_cols].idxmin(axis=1).value_counts()\n",
    "    )\n",
    "\n",
    "winner_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23437b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if returns_stats is None:\n",
    "    print('[Warning] returns_summary_stats.csv not loaded; skipping returns table')\n",
    "    returns_sorted = None\n",
    "else:\n",
    "    returns_sorted = returns_stats.sort_values('std', ascending=False)\n",
    "    returns_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75154876",
   "metadata": {},
   "source": [
    "# Neural Networks for Daily Stock Prediction: An Empirical Study with LSTM and Classical Benchmarks\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This project investigates whether a simple recurrent neural network architecture can meaningfully improve daily stock price forecasts relative to classical time series baselines.\n",
    "\n",
    "I construct a liquid universe of large capitalisation United States equities and major equity indices from 2010 to 2025 using Yahoo Finance adjusted close data. For each symbol I train a univariate Long Short Term Memory (LSTM) network on the historical price series and compare its test set performance with three standard benchmarks: a lag one naive model, a five day moving average, and a twenty day moving average.\n",
    "\n",
    "Models are evaluated out of sample using mean absolute error and root mean squared error on a recent test window. Even though the LSTM is able to fit the training data, the empirical results show that the naive lag one model consistently achieves the lowest test error across all symbols in the universe. The moving average models perform slightly worse than the naive model, and the LSTM rarely outperforms either baseline.\n",
    "\n",
    "These findings are consistent with the view that daily prices of liquid assets behave close to a random walk, so that the best forecast of tomorrow is simply today. The study highlights the importance of strong baselines and careful validation when applying deep learning to financial markets. I conclude with a discussion of potential extensions, including directional accuracy, simple trading rules based on model forecasts, and richer feature sets that incorporate volatility, technical indicators and macro factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6f6cb",
   "metadata": {},
   "source": [
    "## 2. Introduction and motivation\n",
    "\n",
    "Machine learning and deep learning have become very popular in quantitative finance. Recurrent neural networks, and in particular Long Short Term Memory (LSTM) networks, are often proposed as a way to exploit temporal patterns in stock prices. Many introductory papers and online tutorials claim that these models can \"predict\" the stock market more accurately than simple statistical methods.\n",
    "\n",
    "At the same time, classical financial theory states that liquid equity prices follow a process close to a random walk. In such a setting, the conditional expectation of tomorrow price given today information is essentially equal to today price. Under squared error loss the optimal forecast of \\(P_{t+1}\\) is simply \\(P_t\\). This leads to an extremely simple benchmark model, often called the naive or random walk model, that sets\n",
    "\n",
    "\\[\n",
    "\\hat P_{t+1}^{\\text{naive}} = P_t.\n",
    "\\]\n",
    "\n",
    "If this description is accurate, then complex neural networks that see only the same price history should not be able to consistently beat the naive model on purely statistical error metrics.\n",
    "\n",
    "The main objective of this project is to test this claim empirically on a realistic universe of large liquid stocks and indices. The research question is:\n",
    "\n",
    "> Given only the past daily prices of a stock, can an LSTM significantly outperform a naive lag one model and simple moving average baselines on out of sample prediction error?\n",
    "\n",
    "I focus on a univariate setting where each model sees only the history of a single asset. This keeps the methodology transparent and makes it easier to relate the results to classical time series theory. At the same time it provides a useful building block for more advanced multi asset, cross sectional or factor based models in future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c701d2",
   "metadata": {},
   "source": [
    "## 3. Data and universe construction\n",
    "\n",
    "### 3.1 Universe selection\n",
    "\n",
    "The universe consists of 40 large capitalisation equities and several major equity indices and exchange traded funds. The list includes technology names such as AAPL, MSFT, NVDA and AMZN, consumer names such as WMT and MCD, financials such as JPM and GS, energy majors XOM and CVX, and broad market indices such as SPY, QQQ and DIA.\n",
    "\n",
    "These assets were chosen to represent liquid names with long price histories, diverse sector exposures and a range of volatility levels. Many of them are constituents of the S and P 500 or Nasdaq indices and are widely traded by institutional and retail investors.\n",
    "\n",
    "### 3.2 Data source and frequency\n",
    "\n",
    "For each symbol I download daily price history from Yahoo Finance using the `yfinance` Python library. I focus on adjusted close prices which incorporate corporate actions such as splits and dividends. The sample runs from 4 January 2010 to early December 2025, yielding roughly 4 000 trading days for the earliest symbols.\n",
    "\n",
    "From the adjusted close series I construct daily log returns\n",
    "\n",
    "\\[\n",
    "r_t = \\log P_t - \\log P_{t-1}.\n",
    "\\]\n",
    "\n",
    "In the forecasting pipeline the models operate on a scaled version of either prices or returns, but the evaluation metrics are always computed in the original scale so that errors are comparable across models.\n",
    "\n",
    "### 3.3 Universe behaviour\n",
    "\n",
    "The figure below shows each symbol normalised to start at 1 at the beginning of the sample:\n",
    "\n",
    "*(insert `universe_normalized_prices.png` here)*\n",
    "\n",
    "The plot highlights the very strong growth of several technology names such as NVDA, AVGO and TSLA relative to the rest of the universe. It also shows periods of broad market drawdowns such as the Covid shock in 2020 and the inflation and rate hiking cycle in 2022.\n",
    "\n",
    "To understand cross sectional dependence, I compute the correlation matrix of daily returns across all symbols. The heatmap is shown below:\n",
    "\n",
    "*(insert `corr_heatmap.png` here)*\n",
    "\n",
    "Unsurprisingly, broad market indices such as SPY, QQQ, DIA, and the level indices ^GSPC, ^NDX and ^DJI are highly correlated with each other and with large benchmark constituents. Sector pairs such as XOM and CVX, or V and MA, also display strong positive correlation. This structure will matter in future work when I extend the models to use cross sectional information, but in the current project each asset is modelled independently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9a787",
   "metadata": {},
   "source": [
    "### 3.4 Return summary statistics\n",
    "\n",
    "To get a sense of risk and reward, I compute the mean and standard deviation of daily returns for each symbol. Volatile names such as NVDA, TSLA and NFLX exhibit daily return standard deviations above 3 percent, while stable consumer names and indices have much lower values around 1 percent.\n",
    "\n",
    "This confirms that the universe contains a mix of high beta growth stocks and defensive names. It also suggests that forecasting error magnitudes will be larger in absolute terms for the more volatile symbols, which is visible later in the RMSE tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ff81a",
   "metadata": {},
   "source": [
    "## 4. Forecasting models\n",
    "\n",
    "I consider four forecasting models that all operate on the same univariate price series of each asset.\n",
    "\n",
    "### 4.1 Forecast target\n",
    "\n",
    "Let \\(y_t\\) denote the transformed series that the models see, which can be either log price or scaled return. The goal is to forecast \\(y_{t+1}\\) one step ahead using information available up to time \\(t\\).\n",
    "\n",
    "Given a history \\(y_{t-k+1}, \\dots, y_t\\), each model outputs a prediction \\(\\hat y_{t+1}\\). Performance is evaluated on a held out test set using mean absolute error and root mean squared error.\n",
    "\n",
    "### 4.2 Naive lag one model\n",
    "\n",
    "The naive model uses the simplest possible rule:\n",
    "\n",
    "\\[\n",
    "\\hat y_{t+1}^{\\text{naive}} = y_t.\n",
    "\\]\n",
    "\n",
    "This corresponds to assuming that the best guess for tomorrow is simply today, which is optimal for a random walk with independent increments under squared loss.\n",
    "\n",
    "### 4.3 Moving average benchmarks\n",
    "\n",
    "The second and third models are simple moving averages of the recent history:\n",
    "\n",
    "- Five day moving average\n",
    "\n",
    "\\[\n",
    "\\hat y_{t+1}^{\\text{MA5}} = \\frac{1}{5} \\sum_{i=0}^{4} y_{t-i}.\n",
    "\\]\n",
    "\n",
    "- Twenty day moving average\n",
    "\n",
    "\\[\n",
    "\\hat y_{t+1}^{\\text{MA20}} = \\frac{1}{20} \\sum_{i=0}^{19} y_{t-i}.\n",
    "\\]\n",
    "\n",
    "These models smooth short term noise and are widely used in technical analysis as trend filters. However, the smoothing introduces lag, so they may react more slowly to turning points.\n",
    "\n",
    "### 4.4 LSTM neural network\n",
    "\n",
    "The final model is a univariate Long Short Term Memory network. For each asset I construct overlapping windows of length \\(L\\), for example 60 trading days, and use these as inputs to an LSTM that outputs a one step ahead forecast.\n",
    "\n",
    "An LSTM cell maintains an internal hidden state \\(h_t\\) and a cell state \\(c_t\\) that are updated at each time step through a series of gating operations. At a high level, the equations are\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "i_t &= \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\\\\n",
    "f_t &= \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\\\\n",
    "o_t &= \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\\\\n",
    "\\tilde c_t &= \\tanh(W_c x_t + U_c h_{t-1} + b_c) \\\\\n",
    "c_t &= f_t \\odot c_{t-1} + i_t \\odot \\tilde c_t \\\\\n",
    "h_t &= o_t \\odot \\tanh(c_t),\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "where \\(i_t, f_t, o_t\\) are the input, forget and output gates and \\(\\sigma\\) is the logistic function. This architecture allows the network to retain or forget information across long time horizons, which is important in many sequence tasks.\n",
    "\n",
    "In this project I use a single layer LSTM followed by a fully connected layer that maps the final hidden state to a scalar output \\(\\hat y_{t+1}\\). The network is trained with mean squared error loss and the Adam optimiser on the training set of each symbol. Early stopping based on validation loss is used to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3482ae",
   "metadata": {},
   "source": [
    "## 5. Experimental setup\n",
    "\n",
    "For each symbol the full history is split into a training period and a test period. The training set covers roughly the first eighty percent of observations, while the last twenty percent is held out for evaluation. This corresponds to training mainly on data from 2010 to mid 2022 and testing on the more recent regime from 2022 onwards.\n",
    "\n",
    "The baselines and LSTM all receive the same training and test splits for each symbol. For the moving average models the only hyper parameter is the window length. For the LSTM the main hyper parameters are the sequence length, hidden size, learning rate and number of training epochs. I keep these constant across symbols for simplicity and to avoid an unfair advantage from extensive tuning.\n",
    "\n",
    "Performance is measured with:\n",
    "\n",
    "- Mean absolute error (MAE)\n",
    "\n",
    "\\[\n",
    "\\text{MAE} = \\frac{1}{N} \\sum_{t=1}^{N} \\lvert y_t - \\hat y_t \\rvert\n",
    "\\]\n",
    "\n",
    "- Root mean squared error (RMSE)\n",
    "\n",
    "\\[\n",
    "\\text{RMSE} = \\sqrt{ \\frac{1}{N} \\sum_{t=1}^{N} (y_t - \\hat y_t)^2 }.\n",
    "\\]\n",
    "\n",
    "The RMSE is more sensitive to large errors and therefore highlights whether a model occasionally makes very poor predictions.\n",
    "\n",
    "All metrics are computed only on the test period, which the models never see during training, so they provide an honest assessment of generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58e383",
   "metadata": {},
   "source": [
    "## 6. Empirical results\n",
    "\n",
    "### 6.1 Universe behaviour\n",
    "\n",
    "The normalised price plot and return summary statistics confirm that the universe exhibits the usual equity characteristics: long run upward drift with significant drawdowns and a wide dispersion of volatility across names. High growth technology stocks such as NVDA, TSLA and AVGO achieved very large cumulative gains but also display higher daily volatility, while indices and consumer staples are more stable.\n",
    "\n",
    "### 6.2 Error metrics across models\n",
    "\n",
    "The table `metrics_all_symbols.csv` aggregates MAE and RMSE for each symbol and model. For ease of comparison I pivot the RMSE values into `rmse_pivot_table.csv` and compute which model achieves the lowest RMSE for each symbol.\n",
    "\n",
    "Across all 43 symbols in the universe the winner is always the naive lag one model. The five day moving average is usually the second best model, followed by the LSTM, and the twenty day moving average is the weakest. This pattern holds for both RMSE and MAE.\n",
    "\n",
    "In other words, in this experiment the sophisticated neural network never manages to beat a forecast that simply copies yesterday value.\n",
    "\n",
    "The magnitude of the differences is small in absolute terms because all models are effectively tracking a highly persistent series. For example, for SPY the naive model has RMSE around \\(3.6 \\times 10^{-5}\\) while the LSTM has RMSE around \\(6.3 \\times 10^{-5}\\). However, the ranking is consistent across assets.\n",
    "\n",
    "### 6.3 Case study: large indices\n",
    "\n",
    "The figures below illustrate the behaviour for SPY, QQQ and DIA on the test set:\n",
    "\n",
    "*(insert `fig_SPY_test_models.png`, `fig_QQQ_test_models.png`, `fig_AAPL_test_models.png` or similar)*\n",
    "\n",
    "The actual line and all forecast lines sit almost on top of each other. Lag one and the moving averages react very quickly to price movements, while the LSTM output is slightly smoother. The twenty day average lags turning points the most, which explains its higher RMSE.\n",
    "\n",
    "Visually there is no obvious advantage to the LSTM. The predictions are essentially a smoothed version of the recent price history that does not reduce error relative to lag one.\n",
    "\n",
    "### 6.4 Case study: high volatility names\n",
    "\n",
    "For high volatility stocks such as NVDA and AVGO the RMSE values are larger in absolute terms, but the ranking of models is the same. Interestingly, the LSTM sometimes exhibits much higher RMSE than the naive model. For example, for NVDA the LSTM RMSE is about 0.024, compared with 0.0028 for the naive model.\n",
    "\n",
    "This suggests that the neural network occasionally extrapolates too aggressively during sharp swings, while the naive model simply stays anchored to the most recent observation.\n",
    "\n",
    "Overall, the empirical evidence in this dataset strongly supports the view that, when only past prices of a single asset are used, the random walk model is very difficult to beat in terms of point forecast accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be362cf",
   "metadata": {},
   "source": [
    "## 7. Discussion\n",
    "\n",
    "The main finding of this project is that an LSTM trained on univariate daily price history does not outperform a simple lag one naive model on out of sample prediction error. This is consistent with both classical financial theory and the empirical experience of many practitioners, even though it sometimes contradicts the impression given by online tutorials.\n",
    "\n",
    "There are several reasons for this outcome.\n",
    "\n",
    "First, liquid equity prices are highly persistent and approximately follow a random walk with drift. In such a process the conditional expectation of tomorrow price is essentially equal to today price. Under squared error loss this makes the naive model asymptotically optimal. Any nonlinear model that tries to exploit subtle patterns in the noise will on average hurt performance.\n",
    "\n",
    "Second, the LSTM is a relatively complex model with many parameters compared with the effective signal present in the data. With limited training data and strong autocorrelation, the network can easily overfit idiosyncratic fluctuations in the training period and then generalise poorly to the test period.\n",
    "\n",
    "Third, the LSTM in this setup receives only information about a single asset. It cannot exploit cross sectional signals such as relative strength or sector momentum, nor can it condition on macro variables or risk factors. In contrast, many successful applications of deep learning in finance make use of rich sets of predictors rather than a single raw price series.\n",
    "\n",
    "Fourth, forecasting daily prices one step ahead is an extremely hard task from a statistical perspective. Many profitable trading strategies focus instead on predicting volatility, tail risk, regime changes, or cross sectional ranking of returns, where persistence and structure are often stronger.\n",
    "\n",
    "Finally, the results highlight the importance of strong baselines. Without including the naive lag one model and moving average benchmarks, it would be easy to convince oneself that an LSTM with a small RMSE is doing something intelligent. Once the naive model is included, it becomes clear that the neural network mainly replicates the behaviour of a random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e18e66",
   "metadata": {},
   "source": [
    "## 8. Trading oriented extensions\n",
    "\n",
    "The present study focuses on statistical forecast accuracy of the level or return series. From a trading perspective, more interesting questions are related to direction, risk adjusted performance and turnover.\n",
    "\n",
    "Two natural extensions are:\n",
    "\n",
    "1. **Directional accuracy**\n",
    "\n",
    "   Instead of evaluating the exact value of \\(\\hat y_{t+1}\\), we can look at the sign. For each model define a directional forecast\n",
    "\n",
    "   \\[\n",
    "   \\hat s_{t+1} = \\text{sign}(\\hat y_{t+1}).\n",
    "   \\]\n",
    "\n",
    "   We can then compute the hit rate\n",
    "\n",
    "   \\[\n",
    "   \\text{Hit rate} = \\frac{1}{N} \\sum_{t=1}^{N} \\mathbf 1\\{\\hat s_{t+1} = \\text{sign}(y_{t+1})\\}.\n",
    "   \\]\n",
    "\n",
    "   A hit rate significantly above 50 percent would be interesting even if RMSE differences are small.\n",
    "\n",
    "2. **Simple trading strategy**\n",
    "\n",
    "   Given model predictions we can construct a toy trading rule. For example, for each symbol:\n",
    "\n",
    "   - Go long one unit if the model predicts positive return\n",
    "   - Go to cash if the model predicts negative return\n",
    "\n",
    "   The strategy return on day \\(t+1\\) is\n",
    "\n",
    "   \\[\n",
    "   R_{t+1}^{\\text{strategy}} = \\hat s_{t+1} \\cdot r_{t+1}.\n",
    "   \\]\n",
    "\n",
    "   We can cumulate these returns over the test period and compare the equity curves, Sharpe ratios and maximum drawdowns across models.\n",
    "\n",
    "These extensions move the evaluation closer to what a practitioner cares about. However, transaction costs, slippage and position sizing would need to be incorporated before drawing strong conclusions about profitability.\n",
    "\n",
    "For this project I keep the main focus on forecast error, but the trading extension is an attractive direction for future work and can be implemented inside the same pipeline using the saved predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f78aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example sketch, depends on how you saved predictions\n",
    "preds = safe_read_csv(DATA_DIR / 'predictions_example.csv')  # columns: date, symbol, model, y_true, y_pred\n",
    "\n",
    "def strategy_pnl(df, model_name):\n",
    "    sub = df[df[\"Model\"] == model_name].copy()\n",
    "    sub[\"side\"] = (sub[\"y_pred\"] > 0).astype(int) * 2 - 1   # +1 or -1\n",
    "    sub[\"pnl\"] = sub[\"side\"] * sub[\"y_true\"]\n",
    "    return sub[\"pnl\"].cumsum()\n",
    "\n",
    "if preds is None:\n",
    "    print('[Warning] predictions_example.csv not found; skipping example sketch')\n",
    "# then plot for AAPL or SPY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81193cfb",
   "metadata": {},
   "source": [
    "## 8. Streamlit user interface\n",
    "\n",
    "To make the models easier to explore I built a lightweight web application using Streamlit. The app wraps the same data and modelling pipeline in a simple graphical interface so that a user can select a symbol, choose a forecasting model and visualise the results without writing code.\n",
    "\n",
    "### 8.1 Design and architecture\n",
    "\n",
    "The app is implemented in `app/streamlit_app.py`. It relies on three main components:\n",
    "\n",
    "1. **Data layer**  \n",
    "   Historical prices for each symbol are loaded through the same helper functions used in the offline experiments. To avoid repeated downloads and improve responsiveness, the app uses Streamlit caching so that data for a given symbol is fetched only once per session.\n",
    "\n",
    "2. **Model layer**  \n",
    "   For the baseline models, the app recomputes naive and moving average forecasts on the fly. For the LSTM, the app loads a pre trained model for each symbol and generates predictions on the selected test window. This keeps the online computation lightweight because the neural network does not need to be re trained when the user changes settings.\n",
    "\n",
    "3. **Presentation layer**  \n",
    "   The user selects a symbol, date range and model through the sidebar. The main panel displays:\n",
    "   * A time series chart of actual prices overlaid with the model forecast  \n",
    "   * Basic error metrics such as MAE and RMSE for the current selection  \n",
    "   * Optionally, a zoomed in view of the recent test period to highlight differences between models\n",
    "\n",
    "The app also exposes a table of summary metrics computed in the offline diagnostics script so that a user can quickly see which model performs best for a given symbol.\n",
    "\n",
    "### 8.2 Role in the project\n",
    "\n",
    "The Streamlit interface does not change the underlying research results, but it plays two useful roles:\n",
    "\n",
    "* It acts as a sanity check that the models behave as expected, because discrepancies and artefacts are easier to spot visually than in a table.  \n",
    "* It provides an intuitive way for non technical users to interact with the models and see that, in this setting, the simple naive lag one forecast performs at least as well as the LSTM.\n",
    "\n",
    "This kind of research-to-UI bridge is representative of how quantitative tools are often deployed inside a trading firm, where a back end research pipeline feeds into a front end used by portfolio managers and risk teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566ebb3",
   "metadata": {},
   "source": [
    "## 9. Conclusion and limitations\n",
    "\n",
    "This project set out to test whether a univariate LSTM can outperform simple time series benchmarks for daily stock prediction on a realistic universe of liquid equities and indices.\n",
    "\n",
    "Using data from 2010 to 2025 and an out of sample evaluation on the most recent years, I find that the naive lag one model, which simply copies the last observed value, uniformly achieves lower RMSE and MAE than the LSTM and moving average models. The five day moving average is usually second best, while the twenty day average and the LSTM perform worse.\n",
    "\n",
    "The results support the view that daily prices of large liquid assets are very hard to predict from their own history alone. They also illustrate that deep learning models do not automatically generate alpha when applied to financial time series; careful feature design, richer input information and realistic evaluation are essential.\n",
    "\n",
    "The main limitations of the current work are:\n",
    "\n",
    "- Only univariate models are considered. Cross sectional and multi asset architectures could exploit additional structure.\n",
    "- The feature set is restricted to past prices of each asset. No technical indicators, macro variables or volume information are included.\n",
    "- The evaluation focuses on point forecast accuracy rather than trading performance net of costs.\n",
    "- Hyper parameter tuning for the LSTM is intentionally simple to keep the project manageable.\n",
    "\n",
    "These limitations point directly toward future work. Extending the framework to predict volatility, tail risk or cross sectional rankings, and combining price based features with macro and fundamental data, are promising directions for further research.\n",
    "\n",
    "Despite these limitations, the project achieves its main objective: it builds an end to end pipeline for data collection, model training, evaluation and visualisation, and uses it to demonstrate that a widely promoted deep learning architecture does not outperform a well chosen classical benchmark in this setting. This is a valuable lesson for any aspiring quantitative researcher.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde076d",
   "metadata": {},
   "source": [
    "## 10. References\n",
    "\n",
    "- Chevalier, G. (2018). LARNN: Linear Attention Recurrent Neural Network. arXiv preprint arXiv:1808.05578.\n",
    "- Deepika, N., and Bhat, M. N. (2021). An efficient stock market prediction method based on Kalman filter. Journal of the Institution of Engineers Series B.\n",
    "- Dhyani, B. (2020). Stock market forecasting technique using ARIMA model. International Journal of Recent Technology and Engineering.\n",
    "- Various online resources on fundamental analysis and ARIMA modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in UNIVERSE:\n",
    "    df = load_price_history(symbol)\n",
    "    # compute predictions for each model\n",
    "    # y_test, y_pred_lstm, y_pred_naive, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ae518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PRED_PATH = Path('data/notebooks/predictions_all_symbols.csv')\n",
    "all_preds = []  # list of small DataFrames\n",
    "\n",
    "if len(UNIVERSE) == 0:\n",
    "    print('[Warning] UNIVERSE is empty; skipping predictions aggregation')\n",
    "else:\n",
    "    for symbol in UNIVERSE:\n",
    "        # Attempt to load symbol data; skip symbol on failure\n",
    "        try:\n",
    "            df = load_price_history(symbol)\n",
    "        except Exception as e:\n",
    "            print(f'[Warning] failed to load price history for {symbol}: {e}')\n",
    "            continue\n",
    "\n",
    "        # If the variables like y_test are not available in this notebook context, skip\n",
    "        if 'y_test' not in globals():\n",
    "            print('[Warning] y_test not defined in this notebook; skipping per-symbol prediction assembly')\n",
    "            break\n",
    "\n",
    "        preds_sym = pd.DataFrame({\n",
    "            'Date': y_test.index,\n",
    "            'Symbol': symbol,\n",
    "            'y_true': y_test.values,\n",
    "            'LSTM': y_pred_lstm,\n",
    "            'Naive lag1': y_pred_naive,\n",
    "            'MA 5 day': y_pred_ma5,\n",
    "            'MA 20 day': y_pred_ma20,\n",
    "        })\n",
    "        all_preds.append(preds_sym)\n",
    "\n",
    "# at the end of the script\n",
    "if len(all_preds) == 0:\n",
    "    print('[Warning] no predictions assembled; predictions_all_symbols.csv will not be created')\n",
    "else:\n",
    "    preds_all = pd.concat(all_preds, ignore_index=True)\n",
    "    preds_all.to_csv(PRED_PATH, index=False)\n",
    "    print(f'[Diagnostics] Saved predictions to {PRED_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the diagnostics module in a notebook-friendly way\n",
    "import runpy, importlib, sys, pathlib\n",
    "module_name = 'data.notebooks.02_model_diagnostics'\n",
    "try:\n",
    "    # prefer running via module import when the package is on sys.path\n",
    "    importlib.import_module('data')\n",
    "    runpy.run_module(module_name, run_name='__main__')\n",
    "except Exception as e:\n",
    "    # Fallback: run the script by file path if the package import fails\n",
    "    script_path = pathlib.Path('data/notebooks/02_model_diagnostics.py')\n",
    "    if script_path.exists():\n",
    "        print(f'[Info] falling back to executing {script_path}')\n",
    "        runpy.run_path(str(script_path), run_name='__main__')\n",
    "    else:\n",
    "        print(f'[Warning] could not import module {module_name} and {script_path} not found: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185831e",
   "metadata": {},
   "source": [
    "## 9. Simple directional trading strategy based on forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data/notebooks\")\n",
    "preds = pd.read_csv(DATA_DIR / \"predictions_all_symbols.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_directional_strategy(df_symbol, model_col):\n",
    "    \"\"\"\n",
    "    df_symbol: DataFrame for a single symbol, with columns\n",
    "               Date, y_true, and model_col for predictions\n",
    "    model_col: column name with predictions, e.g. \"Naive lag1\" or \"LSTM\"\n",
    "    \"\"\"\n",
    "    df = df_symbol.sort_values(\"Date\").copy()\n",
    "\n",
    "    # position is 1 if predicted return > 0, else 0 (cash)\n",
    "    df[\"position\"] = (df[model_col] > 0).astype(int)\n",
    "\n",
    "    # strategy return is position times realised return\n",
    "    df[\"strategy_ret\"] = df[\"position\"] * df[\"y_true\"]\n",
    "\n",
    "    # cumulative equity curve (starting at 1)\n",
    "    df[\"equity\"] = (1 + df[\"strategy_ret\"]).cumprod()\n",
    "\n",
    "    # simple statistics\n",
    "    hit_rate = ((df[\"y_true\"] * df[model_col]) > 0).mean()\n",
    "    avg_ret = df[\"strategy_ret\"].mean()\n",
    "    vol = df[\"strategy_ret\"].std()\n",
    "    sharpe = avg_ret / vol * (252 ** 0.5) if vol > 0 else 0.0\n",
    "\n",
    "    stats = {\n",
    "        \"hit_rate\": hit_rate,\n",
    "        \"avg_daily_ret\": avg_ret,\n",
    "        \"daily_vol\": vol,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"final_equity\": df[\"equity\"].iloc[-1],\n",
    "    }\n",
    "    return df, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"SPY\"\n",
    "\n",
    "preds_spy = preds[preds[\"Symbol\"] == symbol]\n",
    "\n",
    "models_to_compare = [\"Naive lag1\", \"LSTM\", \"MA 5 day\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for model in models_to_compare:\n",
    "    df_model, stats = evaluate_directional_strategy(preds_spy[[\"Date\", \"y_true\", model]].rename(columns={model: \"pred\"}).assign(Symbol=symbol), \"pred\")\n",
    "    # store stats\n",
    "    results[model] = stats\n",
    "    plt.plot(df_model[\"Date\"], df_model[\"equity\"], label=model)\n",
    "\n",
    "plt.title(f\"{symbol} directional strategy equity curves (long only)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Equity (start = 1)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b281047",
   "metadata": {},
   "source": [
    "The table above shows that, even when we convert forecasts into a simple long only trading rule, the performance differences between models remain modest. In this example the naive lag one forecast again performs at least as well as the LSTM in terms of both final equity and Sharpe ratio, once we ignore transaction costs.\n",
    "\n",
    "This reinforces the earlier conclusion that, given only the past price of a single asset, complex sequence models do not automatically translate into superior trading performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
